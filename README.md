# CSC-2516-413-Final-Project
Contributions

Haoying Wang:
Conducted the training, fine-tuning, and hyperparameter optimization for the RoBERTa model on the Stanford Natural Language Inference (SNLI) dataset.
Performed detailed analysis of the RoBERTa model's performance, focusing on its accuracy and robustness across various hyperparameter configurations.
Contributed to writing and refining the final report, with a specific focus on the sections covering discriminative models and their role in Natural Language Inference tasks.

Shiming Zhang:
Led the training, fine-tuning, and evaluation of the Explainable Phrasal Reasoning (EPR) model.
Conducted experiments to assess the interpretability of EPRâ€™s structured reasoning approach, including human evaluations of faithfulness and plausibility.
Wrote and contributed to the final report by detailing the methodology, results, and trade-offs associated with the EPR model, particularly in balancing accuracy and transparency.

Ian Huang:
Managed the training and evaluation of GPT-3 models, including zero-shot, few-shot, and fine-tuned configurations on the SNLI dataset.
Analyzed the performance and explainability trade-offs for GPT-3, with an emphasis on its adaptability and generation of natural language explanations.
Played a significant role in writing the final report, focusing on generative models and their implications for Natural Language Inference, including discussions on fluency versus faithfulness in generated explanations.
